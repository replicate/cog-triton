# this is an identifier for downloading the model. e.g., 
# https://huggingface.co/<model_id>
model_id: bigcode/starcoder
# this is the name of the trt-llm example directory to use for the build
# See possible examples here: 
example_name: gpt
convert_to_ft:
  script: hf_gpt_convert.py
  output_dir: ./c-model/starcoder/1-gpu
  args:
    # Must be the path to the downloaded model
    # Model will always be downloaded to
    # /src/models/<model_name>/
    in-file: /src/models/bigcode/starcoder
    out-dir: /src/c-model/starcoder
    tensor-parallelism: 1
    storage-type: float16
    processes: 1
    smoothquant: 0.5
build:
  script: build.py
  output_dir: /src/engine_outputs/
  args:
    model_dir: /src/c-model/starcoder/1-gpu
    output_dir: /src/engine_outputs/
    dtype: float16
    use_gemm_plugin: float16
    use_gpt_attention_plugin: 
    paged_kv_cache:
    remove_input_padding:
    int8_kv_cache:
    use_smooth_quant:
hf_token: your_token_here